{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac8e64d-c446-4b4e-80c8-75a31e115c3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Create Lakebase Database Instance \n",
    "- Create a synced table\n",
    "- Create a lakebase native table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b7d9b7fd-23d4-4b9b-ba6a-5d2731be5a7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade databricks-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4192676-1f6d-4611-a001-2d11338f3204",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4f8d04-a31c-411e-9e89-c8ed9e244864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.database import DatabaseInstance, SyncedTableSpec, SyncedTableSchedulingPolicy, SyncedDatabaseTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e1ad90d-cdb2-4bc3-9068-7a8e274024b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lakebase_instance_name = 'zg-mfg-lakebase-demo' # name of the database instance\n",
    "cu = 'CU_1' # size of the database instance\n",
    "node_count = 2 # number of database nodes, need at least 2 for failover\n",
    "\n",
    "catalog_name = 'zg' # UC catalog name\n",
    "pg_db_name = 'pg_mfg_db' # Lakebase database name (similar to UC catalog level)\n",
    "schema_name = 'mfg_lakebase_demo' # name of the UC schema and postgres schema\n",
    "\n",
    "routes_destination_table_name = f\"{catalog_name}.{schema_name}.recommended_routes_synced_table\"\n",
    "routes_source_table_full_name = f\"{catalog_name}.{schema_name}.recommended_routes\"\n",
    "routes_primary_key_columns = [\"part_id\"]\n",
    "\n",
    "parts_backlog_destination_table_name = f\"{catalog_name}.{schema_name}.part_backlog_synced_table\"\n",
    "parts_backlog_source_table_full_name = f\"{catalog_name}.{schema_name}.part_backlog\"\n",
    "parts_backlog_primary_key_columns = [\"part_id\"]\n",
    "\n",
    "pg_table_name = 'assignment_overrides' # native postgres table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c88ba555-5409-44a8-a286-25ec2af2e18d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the workspace client \n",
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7748d9-a10a-43d9-8397-3edc102bfb02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the database instance \n",
    "database_instance = DatabaseInstance(\n",
    "  name=lakebase_instance_name,\n",
    "  capacity=cu,\n",
    "  node_count=node_count\n",
    ")\n",
    "\n",
    "w.database.create_database_instance(\n",
    "  database_instance = database_instance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "285f81fc-f134-448c-bf9d-0e3127ae4a93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# wait for the database instance to become available before creating the synced table\n",
    "w.database.wait_get_database_instance_database_available(name=lakebase_instance_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1099cc82-d304-46cc-be44-e948b4826a1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a synced table for the recommended routes\n",
    "table_spec = SyncedTableSpec(\n",
    "  source_table_full_name=routes_source_table_full_name,\n",
    "  primary_key_columns=routes_primary_key_columns,\n",
    "  scheduling_policy=SyncedTableSchedulingPolicy.TRIGGERED, \n",
    ")\n",
    "\n",
    "synced_table = SyncedDatabaseTable(\n",
    "  name=routes_destination_table_name,\n",
    "  database_instance_name=lakebase_instance_name,\n",
    "  logical_database_name=pg_db_name,\n",
    "  spec=table_spec\n",
    ")\n",
    "\n",
    "w.database.create_synced_database_table(synced_table=synced_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c1ed836-f7d9-4eca-933e-4f241339fafb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "routes_destination_table_name_info = w.database.get_synced_database_table(name=routes_destination_table_name)\n",
    "pipeline_id = routes_destination_table_name_info.data_synchronization_status.pipeline_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "640ae953-425c-4498-b9e9-b1ddee89c49b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a synced table for the part backlog using the same DLT pipeline\n",
    "table_spec = SyncedTableSpec(\n",
    "  existing_pipeline_id=pipeline_id,\n",
    "  source_table_full_name=parts_backlog_source_table_full_name,\n",
    "  primary_key_columns=parts_backlog_primary_key_columns,\n",
    "  scheduling_policy=SyncedTableSchedulingPolicy.TRIGGERED, \n",
    ")\n",
    "\n",
    "synced_table = SyncedDatabaseTable(\n",
    "  name=parts_backlog_destination_table_name,\n",
    "  database_instance_name=lakebase_instance_name,\n",
    "  logical_database_name=pg_db_name,\n",
    "  spec=table_spec\n",
    ")\n",
    "\n",
    "w.database.create_synced_database_table(synced_table=synced_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b8527a-26b5-45d5-80b5-c60bc2666dd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run the pipeline to populate the part_log table\n",
    "run = w.pipelines.start_update(\n",
    "    pipeline_id=pipeline_id,\n",
    "    full_refresh=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0daf3a4b-4977-4362-a42c-18c6d3e82ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a native lakebase (postgres) table\n",
    "import psycopg2\n",
    "import uuid\n",
    "\n",
    "user = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "\n",
    "instance = w.database.get_database_instance(name=lakebase_instance_name)\n",
    "cred = w.database.generate_database_credential(request_id=str(uuid.uuid4()), instance_names=[lakebase_instance_name])\n",
    "\n",
    "# Connection parameters\n",
    "conn = psycopg2.connect(\n",
    "    host = instance.read_write_dns,\n",
    "    dbname = pg_db_name,\n",
    "    user = user,\n",
    "    password = cred.token,\n",
    "    sslmode = \"require\"\n",
    ")\n",
    "\n",
    "# Execute query\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {schema_name}.{pg_table_name} (\n",
    "      part_id VARCHAR(255),\n",
    "      assigned_machine_id VARCHAR(255),\n",
    "      assigned_by VARCHAR(255),\n",
    "      assigned_at TIMESTAMP,\n",
    "      notes TEXT\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    cur.execute(f\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT 1 FROM information_schema.tables\n",
    "        WHERE table_schema = '{schema_name}' AND table_name = '{pg_table_name}'\n",
    "    );\n",
    "    \"\"\")\n",
    "    created = cur.fetchone()[0]\n",
    "    if created:\n",
    "        print(f\"Table {schema_name}.{pg_table_name} has been created or already exists.\")\n",
    "    else:\n",
    "        print(\"Table creation failed or is not visible.\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5614418170457722,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "lakebase_setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
